use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::read_to_string;
use std::path::PathBuf;

use crate::{CoreResult, Error};

/// A query submitted to a model provider for processing.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Query {
    /// The text content of the query.
    pub text: String,
    /// Optional conversation identifier for maintaining context across queries.
    pub conversation_id: Option<String>,
    /// Paths to files that provide additional context for the query.
    pub files_context: Vec<PathBuf>,
    /// Routing context for test infrastructure and debugging.
    #[serde(default)]
    pub routing_context: RoutingContext,
}

impl Query {
    /// Creates a new query with the given text.
    pub fn new<T: Into<String>>(text: T) -> Self {
        Self {
            text: text.into(),
            conversation_id: None,
            files_context: Vec::default(),
            routing_context: RoutingContext::default(),
        }
    }

    /// Adds file paths to provide context for this query.
    #[must_use]
    pub fn with_files(mut self, files: Vec<PathBuf>) -> Self {
        self.files_context = files;
        self
    }

    /// Sets the routing context for this query.
    #[must_use]
    pub fn with_routing_context(mut self, routing_context: RoutingContext) -> Self {
        self.routing_context = routing_context;
        self
    }
}

/// A response generated by a model provider.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Response {
    /// The generated text content.
    pub text: String,
    /// Confidence score for the response (0.0 to 1.0).
    pub confidence: f64,
    /// Token usage statistics for this generation.
    pub tokens_used: TokenUsage,
    /// Name of the provider that generated this response.
    pub provider: String,
    /// Time taken to generate the response in milliseconds.
    pub latency_ms: u64,
}

/// Token usage statistics for a model invocation.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct TokenUsage {
    /// Number of input tokens processed.
    pub input: u64,
    /// Number of output tokens generated.
    pub output: u64,
    /// Number of tokens read from cache.
    pub cache_read: u64,
    /// Number of tokens written to cache.
    pub cache_write: u64,
}

impl TokenUsage {
    /// Returns the sum of all token counts.
    pub fn total(&self) -> u64 {
        self.input + self.output + self.cache_read + self.cache_write
    }
}

/// Context provided to a model for generating responses.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Context {
    /// Files that provide context for model generation.
    pub files: Vec<FileContext>,
    /// System-level instructions for the model.
    pub system_prompt: String,
    /// Optional metadata for test infrastructure (ignored by real providers)
    #[serde(default, skip_serializing_if = "HashMap::is_empty")]
    pub metadata: HashMap<String, String>,
}

impl Context {
    /// Creates a new context with the given system prompt.
    pub fn new<T: Into<String>>(system_prompt: T) -> Self {
        Self {
            files: Vec::default(),
            system_prompt: system_prompt.into(),
            metadata: HashMap::new(),
        }
    }

    /// Adds file contexts to this context.
    #[must_use]
    pub fn with_files(mut self, files: Vec<FileContext>) -> Self {
        self.files = files;
        self
    }

    /// Adds additional content to the system prompt.
    #[must_use]
    pub fn with_additional_content(mut self, content: &str) -> Self {
        self.system_prompt.push_str("\n\n");
        self.system_prompt.push_str(content);
        self
    }

    /// Formats all file contexts as a single string for inclusion in prompts.
    pub fn files_to_string(&self) -> String {
        self.files
            .iter()
            .map(|file| format!("// File: {}\n{}\n", file.path.display(), file.content))
            .collect::<Vec<_>>()
            .join("\n")
    }

    /// Estimates the total token count for this context using a simple heuristic.
    pub fn token_estimate(&self) -> usize {
        let files_len: usize = self.files.iter().map(|file| file.content.len()).sum();
        (self.system_prompt.len() + files_len) / 4
    }
}

/// A file and its content provided as context to a model.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileContext {
    /// Path to the file.
    pub path: PathBuf,
    /// Text content of the file.
    pub content: String,
}

impl FileContext {
    /// # Errors
    /// Returns an error if the file cannot be read
    pub fn from_path(path: &PathBuf) -> CoreResult<Self> {
        let content =
            read_to_string(path).map_err(|_| Error::FileNotFound(path.display().to_string()))?;

        Ok(Self {
            path: path.clone(),
            content,
        })
    }

    /// Creates a new file context with the given path and content.
    pub fn new(path: PathBuf, content: String) -> Self {
        Self { path, content }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use merlin_deps::anyhow::Result;
    use merlin_deps::serde_json::{from_str, to_string};
    use merlin_deps::tempfile::TempDir;
    use std::fs::write;

    // REMOVED: test_query_new - Constructor test

    /// Tests query creation with file context.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_query_with_files() {
        let files = vec![PathBuf::from("file1.rs"), PathBuf::from("file2.rs")];
        let query = Query::new("test").with_files(files.clone());
        assert_eq!(query.files_context, files);
    }

    /// Tests query serialization and deserialization round-trip.
    ///
    /// # Errors
    /// Returns an error if serialization or deserialization fails.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_query_serialization() -> Result<()> {
        let query = Query::new("test query").with_files(vec![PathBuf::from("test.rs")]);
        let json = to_string(&query)?;
        let deserialized: Query = from_str(&json)?;
        assert_eq!(query.text, deserialized.text);
        assert_eq!(query.files_context, deserialized.files_context);
        Ok(())
    }

    /// Tests token usage total calculation.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_token_usage_total() {
        let usage = TokenUsage {
            input: 100,
            output: 50,
            cache_read: 20,
            cache_write: 10,
        };
        assert_eq!(usage.total(), 180);
    }

    // REMOVED: test_token_usage_default - Constructor test

    // REMOVED: test_context_new - Constructor test

    /// Tests context creation with file attachments.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_context_with_files() {
        let files = vec![FileContext::new(
            PathBuf::from("test.rs"),
            "content".to_owned(),
        )];
        let context = Context::new("prompt").with_files(files);
        assert_eq!(context.files.len(), 1);
        assert_eq!(context.files[0].path, PathBuf::from("test.rs"));
    }

    /// Tests context file serialization to string format.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_context_files_to_string() {
        let files = vec![
            FileContext::new(PathBuf::from("file1.rs"), "content1".to_owned()),
            FileContext::new(PathBuf::from("file2.rs"), "content2".to_owned()),
        ];
        let context = Context::new("prompt").with_files(files);
        let result = context.files_to_string();
        assert!(result.contains("// File: file1.rs"));
        assert!(result.contains("content1"));
        assert!(result.contains("// File: file2.rs"));
        assert!(result.contains("content2"));
    }

    /// Tests context token count estimation.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_context_token_estimate() {
        let files = vec![FileContext::new(PathBuf::from("test.rs"), "a".repeat(100))];
        let context = Context::new("prompt").with_files(files);
        // (6 + 100) / 4 = 26
        assert_eq!(context.token_estimate(), 26);
    }

    // REMOVED: test_file_context_new - Constructor test

    /// Tests loading file context from filesystem path.
    ///
    /// # Errors
    /// Returns an error if file operations fail.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_file_context_from_path() -> Result<()> {
        let temp_dir = TempDir::new()?;
        let file_path = temp_dir.path().join("test.txt");
        write(&file_path, "test content")?;

        let file_context = FileContext::from_path(&file_path)?;
        assert_eq!(file_context.path, file_path);
        assert_eq!(file_context.content, "test content");
        Ok(())
    }

    /// Tests error handling when loading file context from nonexistent path.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_file_context_from_path_not_found() {
        let path = PathBuf::from("nonexistent.txt");
        let result = FileContext::from_path(&path);
        assert!(result.is_err());
        if let Err(err) = result {
            assert!(matches!(err, Error::FileNotFound(_)));
        }
    }

    /// Tests response serialization and deserialization round-trip.
    ///
    /// # Errors
    /// Returns an error if serialization or deserialization fails.
    ///
    /// # Panics
    /// Panics if assertions fail during test execution.
    #[test]
    fn test_response_serialization() -> Result<()> {
        let response = Response {
            text: "response text".to_owned(),
            confidence: 0.95,
            tokens_used: TokenUsage {
                input: 100,
                output: 50,
                cache_read: 0,
                cache_write: 0,
            },
            provider: "test-provider".to_owned(),
            latency_ms: 250,
        };

        let json = to_string(&response)?;
        let deserialized: Response = from_str(&json)?;
        assert_eq!(response.text, deserialized.text);
        assert!((response.confidence - deserialized.confidence).abs() < f64::EPSILON);
        assert_eq!(response.provider, deserialized.provider);
        Ok(())
    }
}

/// Routing context for tracking execution flow and testing.
///
/// This context is populated by the agent during execution and used by
/// the test infrastructure to match expected routing decisions.
#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
pub struct RoutingContext {
    /// What type of work is this query for?
    pub context_type: ContextType,
    /// What prompt strategy is being used?
    pub prompt_type: PromptType,
    /// Estimated difficulty level (1-10).
    pub estimated_difficulty: Option<u8>,
    /// Which retry attempt is this (0 for first attempt)?
    pub retry_attempt: u8,
    /// Result classification from previous attempt if this is a retry.
    pub previous_result: Option<ExecutionResult>,
}

impl Default for RoutingContext {
    fn default() -> Self {
        Self {
            context_type: ContextType::Conversation,
            prompt_type: PromptType::Design,
            estimated_difficulty: None,
            retry_attempt: 0,
            previous_result: None,
        }
    }
}

/// Type of context or work being performed.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ContextType {
    /// Initial task analysis and decomposition into steps.
    TaskDecomposition,
    /// Executing a specific step from a task list.
    StepExecution,
    /// Validation or verification of results.
    Validation,
    /// Error recovery or debugging.
    ErrorRecovery,
    /// General conversation or query response.
    Conversation,
}

/// Type of prompt being used for this query.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum PromptType {
    /// Standard design and implementation prompt.
    Design,
    /// Debug and error analysis prompt.
    Debug,
    /// Validation and verification prompt.
    Validation,
    /// Planning and decomposition prompt.
    Planning,
}

/// Execution result classification for retry logic.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ExecutionResult {
    /// Soft error - retry with same tier but different prompt.
    SoftError,
    /// Hard error - escalate to higher tier.
    HardError,
}
